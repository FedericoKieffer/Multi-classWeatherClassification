{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "CLx59xV87qrC",
    "outputId": "c0228889-b89a-44d3-9d86-fac4ea5a9dc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.15.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from google.colab import drive\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
    "                         Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D,\\\n",
    "                         UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import applications\n",
    "from keras.models import Model, Input\n",
    "\n",
    "print(\"Tensorflow version %s\" %tf.__version__)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "xZWx-DBx7yPy",
    "outputId": "f44bc1a8-8e95-4dc0-e79c-1a02fd77f0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "datadir = '/content/drive/My Drive/MWI-public-custom'\n",
    "trainingset = datadir+'/train/'\n",
    "testset = datadir + '/test/'\n",
    "BlindTestSet = datadir + '/WeatherBlindTestSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "B7CjVRJZ7567",
    "outputId": "81840ab7-8b2c-43aa-ae11-a60f57526540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "#CREATE TRAINING SET\n",
    "\n",
    "\n",
    "training_set=[]\n",
    "PIXELS=200\n",
    "categories=[\"HAZE\", \"RAINY\", \"SNOWY\", \"SUNNY\"]\n",
    "\n",
    "def create_training_set():\n",
    "    for category in categories:\n",
    "    path = os.path.join(trainingset, category) #path to HAZE, RAINY, SNOWY or SUNNY\n",
    "    class_number = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR) #path to images within each class\n",
    "        new_array = cv2.resize(img_array, (PIXELS, PIXELS))\n",
    "        training_set.append([new_array, class_number])\n",
    "\n",
    "create_training_set()\n",
    "print(len(training_set))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "EE8q3QI77-S6",
    "outputId": "637e84fc-6808-4b6a-cad5-402ca9cebf8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "#CREATE AUGMENTED TRAINING SET\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "augmented_training_set=[]\n",
    "\n",
    "def create_augmented_training_set():\n",
    "    for category in categories:\n",
    "    path = os.path.join(trainingset, category) #path to HAZE, RAINY, SNOWY or SUNNY\n",
    "    class_number = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        #Add original image to dataset\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR) #path to images within each class\n",
    "        new_array = cv2.resize(img_array, (PIXELS, PIXELS))\n",
    "        augmented_training_set.append([new_array/255, class_number]) #import already normalized color images\n",
    "        #Add Spectral Image to dataset\n",
    "        spectral_image = cv2.applyColorMap(new_array, cv2.COLORMAP_RAINBOW)\n",
    "        augmented_training_set.append([spectral_image/255, category])\n",
    "        #Add blurred version of the image to the dataset\n",
    "        blurred_image = cv2.GaussianBlur(new_array, (5,5), cv2.BORDER_DEFAULT) \n",
    "        augmented_training_set.append([blurred_image/255, category])\n",
    "        #Add edge images\n",
    "        edge_image = cv2.Canny(new_array, 100, 200)\n",
    "        edge_image = color.gray2rgb(edge_image)\n",
    "        augmented_training_set.append([edge_image/255, category])\n",
    "        #Compute FFT\n",
    "        img_transform = new_array\n",
    "        img_transform = color.rgb2gray(img_transform)\n",
    "        f = np.fft.fft2(img_transform)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "        #Apply HPF and IFFT\n",
    "        rows, cols= img_transform.shape\n",
    "        crow,ccol= round(rows/2) , round(cols/2)\n",
    "        fshift[crow-30:crow+30, ccol-30:ccol+30] = 0\n",
    "        f_ishift = np.fft.ifftshift(fshift)\n",
    "        img_back = np.fft.ifft2(f_ishift)\n",
    "        img_back = np.abs(img_back)\n",
    "        #Get back to a \"color\" image \n",
    "        img_back = color.gray2rgb(img_back)\n",
    "        #augmented_training_set.append([img_back, category])\n",
    "    \n",
    "\n",
    "create_augmented_training_set()\n",
    "print(len(augmented_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "u-I5cgRX_Ltt",
    "outputId": "35b74fe0-4777-4325-b58b-eb301a505d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "#CREATE TEST SET\n",
    "\n",
    "test_set=[]\n",
    "PIXELS=200\n",
    "categories=[\"HAZE\", \"RAINY\", \"SNOWY\", \"SUNNY\"]\n",
    "\n",
    "def create_test_set():\n",
    "    for category in categories:\n",
    "    path = os.path.join(testset, category) #path to HAZE, RAINY, SNOWY or SUNNY\n",
    "    class_number = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR) #path to images within each class\n",
    "        new_array = cv2.resize(img_array, (PIXELS, PIXELS))\n",
    "        test_set.append([new_array, category])\n",
    "\n",
    "create_test_set()\n",
    "print(len(test_set))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alWSaOSw8gvc"
   },
   "outputs": [],
   "source": [
    "#SHUFFLE THE DATA\n",
    "\n",
    "random.shuffle(training_set)\n",
    "random.shuffle(test_set)\n",
    "random.shuffle(augmented_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "kyzZEDzf8h4y",
    "outputId": "32cd84b0-0713-4acb-afd6-865455962c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNOWY\n"
     ]
    }
   ],
   "source": [
    "#SEPARATE FEATURES AND LABELS\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for features, label in training_set:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "for features, label in test_set:\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "x_train_aug=[]\n",
    "y_train_aug=[]\n",
    "\n",
    "for features, label in augmented_training_set:\n",
    "    x_train_aug.append(features)\n",
    "    y_train_aug.append(label)\n",
    "\n",
    "#Convert features and labels to NumpyArrays\n",
    "x_train=np.array(x_train).reshape(-1, PIXELS, PIXELS, 3)\n",
    "x_test=np.array(x_test).reshape(-1, PIXELS, PIXELS, 3)\n",
    "x_train_aug=np.array(x_train_aug).reshape(-1, PIXELS, PIXELS, 3)\n",
    "\n",
    "y_train=np.array(y_train)\n",
    "y_train_aug=np.array(y_train_aug)\n",
    "\n",
    "#Normalize training and test set\n",
    "x_test=x_test/255\n",
    "x_train=x_train/255\n",
    "\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a4EB9SR8v0P"
   },
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "\n",
    "from keras import applications\n",
    "from keras.models import Model, Input\n",
    "\n",
    "#Download the structure of the pre-trained model we want to make use of\n",
    "\n",
    "def load_backbone_net(input_shape):\n",
    "    \n",
    "    # define input tensor\n",
    "    input0 = Input(shape=input_shape)\n",
    "    print(input0)\n",
    "\n",
    "    # load a pretrained model on imagenet without the final dense layer\n",
    "    feature_extractor = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=input0)   \n",
    "    feature_extractor = feature_extractor.output\n",
    "    feature_extractor = Model(input=input0, output=feature_extractor)\n",
    "    feature_extractor.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return feature_extractor\n",
    "\n",
    "\n",
    "def transferNet(feature_extractor, num_classes, output_layer_name, trainable_layers):\n",
    "    \n",
    "    # get the original input layer tensor\n",
    "    input_t = feature_extractor.get_layer(index=0).input\n",
    "\n",
    "    # set the feture extractor layers as non-trainable\n",
    "    for idx,layer in enumerate(feature_extractor.layers):\n",
    "        if layer.name in trainable_layers:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # get the output tensor from a layer of the feature extractor\n",
    "    output_extractor = feature_extractor.get_layer(name = output_layer_name).output\n",
    "    \n",
    "    #output_extractor = MaxPooling2D(pool_size=(4,4))(output_extractor)\n",
    "\n",
    "    # flat the output of a Conv layer\n",
    "    flatten = Flatten()(output_extractor) \n",
    "    flatten_norm = BatchNormalization()(flatten)\n",
    "\n",
    "    # add a Dense layer\n",
    "    dense = Dropout(0.4)(flatten_norm)\n",
    "    dense = Dense(4096, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    \n",
    "    # add a Dense layer\n",
    "    dense = Dropout(0.4)(dense)\n",
    "    dense = Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "\n",
    "    # add a Dense layer\n",
    "    dense = Dropout(0.4)(dense)\n",
    "    dense = Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "\n",
    "    # add the final output layer\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(num_classes, activation='softmax')(dense)\n",
    "    \n",
    "\n",
    "    model = Model(input=input_t, output=dense, name=\"transferNet\")\n",
    "    \n",
    "  \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# load the pre-trained model\n",
    "feature_extractor = load_backbone_net(x_train.shape[1:])\n",
    "feature_extractor.summary()\n",
    "\n",
    "\n",
    "# choose the layer from which you can get the features (block5_pool the end, glob_pooling to get the pooled version of the output)\n",
    "name_output_extractor = \"block5_pool\"\n",
    "trainable_layers = [\"block5_conv3\"]\n",
    "\n",
    "# build the transfer model\n",
    "transfer_model = transferNet(feature_extractor, 4, name_output_extractor, trainable_layers)\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NRK-aIhA28I"
   },
   "outputs": [],
   "source": [
    "#TRAINING SETUP\n",
    "\n",
    "nepochs = 20       # nr. of learning steps\n",
    "batch_size = 16    # batch_size\n",
    "\n",
    "model = transfer_model\n",
    "y_train_aug1 = keras.utils.to_categorical(y_train_aug, 4)\n",
    "y_train1 = keras.utils.to_categorical(y_train, 4)\n",
    "y_test1 = keras.utils.to_categorical(y_test, 4)\n",
    "stopping = callbacks.EarlyStopping(monitor='val_acc', patience=4) # early stopping condition \n",
    "\n",
    "h=model.fit(x_train_aug, y_train_aug1, batch_size=batch_size, epochs=nepochs, validation_split=0.2, validation_data=(x_test, y_test1), callbacks=[stopping]) #y_train_aug1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1X0GJCoJCWt"
   },
   "outputs": [],
   "source": [
    "#PERFORMANCE METRICS PLOT\n",
    "\n",
    "num_classes=4\n",
    "preds= model.predict(x_test)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=None, sample_weight=None)\n",
    "print(cm)\n",
    "y_pred = keras.utils.to_categorical(y_pred, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(classification_report(y_test, y_pred, labels=None, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-frKtunI7_9K"
   },
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX PLOT\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = 'YlOrRd'\n",
    "cmap = 'PuBuGn'\n",
    "cmap = 'inferno'\n",
    "cmap = 'Oranges'\n",
    "\n",
    "array =[[73,  0,  21,  6],\n",
    " [12, 37, 46,  5],\n",
    " [11,  3, 75, 11],\n",
    " [8, 1,  7, 84]] \n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"1234\"],\n",
    "                  columns = [i for i in \"1234\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, cmap= 'YlOrRd', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NN78yR8K_vm"
   },
   "outputs": [],
   "source": [
    "#LOSS AND ACCURACY PLOTS\n",
    "\n",
    "#Loss comparision\n",
    "plt.plot(h.history['loss'],'r')\n",
    "plt.plot(h.history['val_loss'],'b')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle('Model loss comparison', fontsize=14)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Accuracy comparison\n",
    "plt.plot(h.history['acc'],'r')\n",
    "plt.plot(h.history['val_acc'],'b')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle('Model accuracy comparison', fontsize=14)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqYAS_roqLT8"
   },
   "outputs": [],
   "source": [
    "#SAVE THE MODEL\n",
    "\n",
    "models_dir = datadir + '/models/'\n",
    "\n",
    "def savemodel(model, problem):\n",
    "    filename = os.path.join(models_dir, '%s.h5' %problem)\n",
    "    model.save(filename)\n",
    "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\n",
    "\n",
    "# Save the model\n",
    "savemodel(model,'VGG-16_FineTune_20epochs_augmented data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFWmXuABJMu-"
   },
   "outputs": [],
   "source": [
    "#PREDICTIONS ON BLIND TEST SET\n",
    "\n",
    "import csv\n",
    "predictions=[]\n",
    "\n",
    "def make_predictions():\n",
    "    k=0\n",
    "    for img in os.listdir(BlindTestSet):\n",
    "        img_array = cv2.imread(os.path.join(BlindTestSet, img), cv2.IMREAD_COLOR) #path to images within BlindTestSet\n",
    "        new_array = cv2.resize(img_array/255, (PIXELS, PIXELS))\n",
    "        new_array=np.array(new_array).reshape(-1, PIXELS, PIXELS, 3)\n",
    "        ynew = model.predict(new_array)\n",
    "        predictions.insert(k, ynew)\n",
    "        k+=1\n",
    "\n",
    "    #Write those predictions on a csv file\n",
    "\n",
    "    with open('predictions.csv', 'w') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(predictions)\n",
    "    csvFile.close()\n",
    "\n",
    "make_predictions()\n",
    "print(len(predictions)) \n",
    "print(predictions[1])     "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Problem2-TransferLearning ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
